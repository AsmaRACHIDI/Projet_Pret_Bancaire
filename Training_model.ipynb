{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c64819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import  pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb037e2",
   "metadata": {},
   "source": [
    "# Récupération du dataframe nettoyé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b6b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Asma\\Documents\\ExoSimplon\\Sem15_Grand_Projet\\Data\\train_u6lujuX_CVtuZ9i.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeccf2b",
   "metadata": {},
   "source": [
    "# TRAIN/TEST Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d669be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c6932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5), dpi=100)\n",
    "plt.title(\"Distribution des données\")\n",
    "plt.hist(y, label=\"jeu total\")\n",
    "plt.hist(y_train, label=\"jeu d'apprentissage\")\n",
    "plt.hist(y_test, label=\"jeu de test\")\n",
    "plt.xlabel(\"Valeur du logement\")\n",
    "plt.ylabel(\"Nombre d'exemples\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33764bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd05779",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5492594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df3158",
   "metadata": {},
   "source": [
    "* Features Scaling \n",
    "\n",
    " transformer les variables continues en utilsant MinMaxScaler\n",
    " \n",
    " https://towardsdatascience.com/what-is-feature-scaling-why-is-it-important-in-machine-learning-2854ae877048\n",
    " \n",
    " https://medium.com/codex/feature-scaling-in-machine-learning-e86b360d1c31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd88cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "#TBC\n",
    "scaled = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe412b0",
   "metadata": {},
   "source": [
    "# Training model choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e31c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def accuracy(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    predict = model.predict(X_test)\n",
    "    return y_test, predict\n",
    "\n",
    "model1 = XGBRegressor()\n",
    "model2 = RandomForestRegressor()\n",
    "model3 = SVC()\n",
    "model4 = LogisticRegression()\n",
    "model5 = KNeighborsRegressor()\n",
    "model6 = SGDRegressor()\n",
    "model7 = DecisionTreeRegressor()\n",
    "model8 = GaussianNB()\n",
    "model10= AdaBoostRegressor()\n",
    "#model11=AdaBoostClassifier()\n",
    "    \n",
    "models=[model1,model2,model5,model6,model7,model10]\n",
    "i=0\n",
    "\n",
    "for model in models:\n",
    "    i+=1\n",
    "    y_test, predict=accuracy(model)\n",
    "    print(\"Model \", i,\":\", model)\n",
    "    print('mean_squared_error score:',mean_squared_error(y_test, predict))\n",
    "    #print('F1 score:',f1_score(y_test, predict))\n",
    "    \n",
    "model2.fit(X_train, y_train)\n",
    "model_retenu=model2.predict(X_test)\n",
    "print('\\nmean_squared_error score final:',mean_squared_error(y_test, model2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5eafe",
   "metadata": {},
   "source": [
    "# Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9434b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "# Save the trained model as a pickle string.\n",
    "with open('model2.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model_retenu, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[[2,2,2,2,2,2,2]]\n",
    "model_retenu=model2.predict(test)\n",
    "model_retenu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
